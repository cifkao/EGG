{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import base64\n",
    "import ctypes\n",
    "import collections\n",
    "import itertools\n",
    "import shlex\n",
    "import traceback\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "import egg\n",
    "from egg.zoo.basic_games.data_readers import AttrValClassDataset\n",
    "from egg.zoo.basic_games import play_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_TRAIN = \"../../data/sum5.train.train\"\n",
    "PATH_VAL = \"../../data/sum5.train.val\"\n",
    "PATH_TEST = \"../../data/sum5.test\"\n",
    "N_VALUES = 5\n",
    "N_CLASSES = N_VALUES * 2 - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, test_loader = [\n",
    "    torch.utils.data.DataLoader(\n",
    "        AttrValClassDataset(\n",
    "            path=path,\n",
    "            n_values=N_VALUES,\n",
    "        ),\n",
    "        batch_size=32,\n",
    "        shuffle=False,\n",
    "        num_workers=1,\n",
    "    )\n",
    "    for path in [PATH_TRAIN, PATH_TEST]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_game(exp_dir):\n",
    "    with open(Path(exp_dir) / \"args\") as f:\n",
    "        args = shlex.split(f.read())\n",
    "    opts = play_sum.get_params(args)\n",
    "\n",
    "    # Make the trainer load the checkpoint instead of writing it\n",
    "    assert opts.checkpoint_dir\n",
    "    opts.load_from_checkpoint = str(Path(opts.checkpoint_dir) / \"final.tar\")\n",
    "    opts.checkpoint_dir = None\n",
    "    opts.tensorboard = False\n",
    "\n",
    "    game = play_sum.main(args, opts=opts, train=False)\n",
    "    game.eval()\n",
    "    return game, opts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def interact(game, data_loader):\n",
    "    interactions = []\n",
    "    for sender_input, labels in data_loader:\n",
    "        with torch.no_grad():\n",
    "            interactions.append(game(sender_input.cuda(), labels.cuda())[1].to(\"cpu\"))\n",
    "    return egg.core.Interaction.from_iterable(interactions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def balanced_accuracy(interaction):\n",
    "    class_hits = np.bincount(interaction.labels, weights=interaction.aux[\"acc\"])\n",
    "    class_counts = np.bincount(interaction.labels)\n",
    "    class_accuracies = class_hits[class_counts > 0] / class_counts[class_counts > 0]\n",
    "    return class_accuracies.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, fp16=False, load_from_checkpoint='vs9_20210728-011522/final.tar', lr=0.001, max_len=1, mode='rf', n_attributes=None, n_epochs=1000, n_values=5, no_cuda=False, optimizer='adam', preemptable=False, print_validation_events=False, random_seed=2125479434, receiver_cell='rnn', receiver_embedding=10, receiver_hidden=100, receiver_layers=2, rnn=False, sender_cell='rnn', sender_embedding=10, sender_entropy_coeff=0.1, sender_hidden=100, sender_layers=2, temperature=1.0, tensorboard=False, tensorboard_dir='vs9_20210728-011522', train_data='../../data/sum5.train.train', update_freq=1, validation_batch_size=32, validation_data='../../data/sum5.train.val', validation_freq=20, vocab_size=9)\n",
      "# Initializing model, trainer, and optimizer from vs9_20210728-011522/final.tar\n",
      "# loading trainer state from vs9_20210728-011522/final.tar\n",
      "Namespace(batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, fp16=False, load_from_checkpoint='vs25_20210728-010145/final.tar', lr=0.001, max_len=1, mode='rf', n_attributes=None, n_epochs=1000, n_values=5, no_cuda=False, optimizer='adam', preemptable=False, print_validation_events=False, random_seed=1440499137, receiver_cell='rnn', receiver_embedding=10, receiver_hidden=100, receiver_layers=2, rnn=False, sender_cell='rnn', sender_embedding=10, sender_entropy_coeff=0.1, sender_hidden=100, sender_layers=2, temperature=1.0, tensorboard=False, tensorboard_dir='vs25_20210728-010145', train_data='../../data/sum5.train.train', update_freq=1, validation_batch_size=32, validation_data='../../data/sum5.train.val', validation_freq=20, vocab_size=25)\n",
      "# Initializing model, trainer, and optimizer from vs25_20210728-010145/final.tar\n",
      "# loading trainer state from vs25_20210728-010145/final.tar\n",
      "Namespace(batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, fp16=False, load_from_checkpoint='vs9_20210728-012513/final.tar', lr=0.001, max_len=1, mode='rf', n_attributes=None, n_epochs=1000, n_values=5, no_cuda=False, optimizer='adam', preemptable=False, print_validation_events=False, random_seed=1882480905, receiver_cell='rnn', receiver_embedding=10, receiver_hidden=100, receiver_layers=2, rnn=False, sender_cell='rnn', sender_embedding=10, sender_entropy_coeff=0.1, sender_hidden=100, sender_layers=2, temperature=1.0, tensorboard=False, tensorboard_dir='vs9_20210728-012513', train_data='../../data/sum5.train.train', update_freq=1, validation_batch_size=32, validation_data='../../data/sum5.train.val', validation_freq=20, vocab_size=9)\n",
      "# Initializing model, trainer, and optimizer from vs9_20210728-012513/final.tar\n",
      "# loading trainer state from vs9_20210728-012513/final.tar\n",
      "Namespace(batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, fp16=False, load_from_checkpoint='vs25_20210728-011052/final.tar', lr=0.001, max_len=1, mode='rf', n_attributes=None, n_epochs=1000, n_values=5, no_cuda=False, optimizer='adam', preemptable=False, print_validation_events=False, random_seed=465575092, receiver_cell='rnn', receiver_embedding=10, receiver_hidden=100, receiver_layers=2, rnn=False, sender_cell='rnn', sender_embedding=10, sender_entropy_coeff=0.1, sender_hidden=100, sender_layers=2, temperature=1.0, tensorboard=False, tensorboard_dir='vs25_20210728-011052', train_data='../../data/sum5.train.train', update_freq=1, validation_batch_size=32, validation_data='../../data/sum5.train.val', validation_freq=20, vocab_size=25)\n",
      "# Initializing model, trainer, and optimizer from vs25_20210728-011052/final.tar\n",
      "# loading trainer state from vs25_20210728-011052/final.tar\n",
      "Namespace(batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, fp16=False, load_from_checkpoint='vs9_20210728-012034/final.tar', lr=0.001, max_len=1, mode='rf', n_attributes=None, n_epochs=1000, n_values=5, no_cuda=False, optimizer='adam', preemptable=False, print_validation_events=False, random_seed=342440360, receiver_cell='rnn', receiver_embedding=10, receiver_hidden=100, receiver_layers=2, rnn=False, sender_cell='rnn', sender_embedding=10, sender_entropy_coeff=0.1, sender_hidden=100, sender_layers=2, temperature=1.0, tensorboard=False, tensorboard_dir='vs9_20210728-012034', train_data='../../data/sum5.train.train', update_freq=1, validation_batch_size=32, validation_data='../../data/sum5.train.val', validation_freq=20, vocab_size=9)\n",
      "# Initializing model, trainer, and optimizer from vs9_20210728-012034/final.tar\n",
      "# loading trainer state from vs9_20210728-012034/final.tar\n",
      "Namespace(batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, fp16=False, load_from_checkpoint='vs50_20210728-014041/final.tar', lr=0.001, max_len=1, mode='rf', n_attributes=None, n_epochs=1000, n_values=5, no_cuda=False, optimizer='adam', preemptable=False, print_validation_events=False, random_seed=407623786, receiver_cell='rnn', receiver_embedding=10, receiver_hidden=100, receiver_layers=2, rnn=False, sender_cell='rnn', sender_embedding=10, sender_entropy_coeff=0.1, sender_hidden=100, sender_layers=2, temperature=1.0, tensorboard=False, tensorboard_dir='vs50_20210728-014041', train_data='../../data/sum5.train.train', update_freq=1, validation_batch_size=32, validation_data='../../data/sum5.train.val', validation_freq=20, vocab_size=50)\n",
      "# Initializing model, trainer, and optimizer from vs50_20210728-014041/final.tar\n",
      "# loading trainer state from vs50_20210728-014041/final.tar\n",
      "Namespace(batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, fp16=False, load_from_checkpoint='vs50_20210728-012642/final.tar', lr=0.001, max_len=1, mode='rf', n_attributes=None, n_epochs=1000, n_values=5, no_cuda=False, optimizer='adam', preemptable=False, print_validation_events=False, random_seed=1278082654, receiver_cell='rnn', receiver_embedding=10, receiver_hidden=100, receiver_layers=2, rnn=False, sender_cell='rnn', sender_embedding=10, sender_entropy_coeff=0.1, sender_hidden=100, sender_layers=2, temperature=1.0, tensorboard=False, tensorboard_dir='vs50_20210728-012642', train_data='../../data/sum5.train.train', update_freq=1, validation_batch_size=32, validation_data='../../data/sum5.train.val', validation_freq=20, vocab_size=50)\n",
      "# Initializing model, trainer, and optimizer from vs50_20210728-012642/final.tar\n",
      "# loading trainer state from vs50_20210728-012642/final.tar\n",
      "Namespace(batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, fp16=False, load_from_checkpoint='vs9_20210728-011103/final.tar', lr=0.001, max_len=1, mode='rf', n_attributes=None, n_epochs=1000, n_values=5, no_cuda=False, optimizer='adam', preemptable=False, print_validation_events=False, random_seed=1918456882, receiver_cell='rnn', receiver_embedding=10, receiver_hidden=100, receiver_layers=2, rnn=False, sender_cell='rnn', sender_embedding=10, sender_entropy_coeff=0.1, sender_hidden=100, sender_layers=2, temperature=1.0, tensorboard=False, tensorboard_dir='vs9_20210728-011103', train_data='../../data/sum5.train.train', update_freq=1, validation_batch_size=32, validation_data='../../data/sum5.train.val', validation_freq=20, vocab_size=9)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Initializing model, trainer, and optimizer from vs9_20210728-011103/final.tar\n",
      "# loading trainer state from vs9_20210728-011103/final.tar\n",
      "Namespace(batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, fp16=False, load_from_checkpoint='vs80_20210727-204454/final.tar', lr=0.001, max_len=1, mode='rf', n_attributes=None, n_epochs=1000, n_values=5, no_cuda=False, optimizer='adam', preemptable=False, print_validation_events=False, random_seed=268405226, receiver_cell='rnn', receiver_embedding=10, receiver_hidden=100, receiver_layers=2, rnn=False, sender_cell='rnn', sender_embedding=10, sender_entropy_coeff=0.1, sender_hidden=100, sender_layers=2, temperature=1.0, tensorboard=False, tensorboard_dir='vs80_20210727-204454', train_data='../../data/sum5.train.train', update_freq=1, validation_batch_size=32, validation_data='../../data/sum5.train.val', validation_freq=20, vocab_size=80)\n",
      "# Initializing model, trainer, and optimizer from vs80_20210727-204454/final.tar\n",
      "# loading trainer state from vs80_20210727-204454/final.tar\n",
      "Namespace(batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, fp16=False, load_from_checkpoint='vs25_20210728-010622/final.tar', lr=0.001, max_len=1, mode='rf', n_attributes=None, n_epochs=1000, n_values=5, no_cuda=False, optimizer='adam', preemptable=False, print_validation_events=False, random_seed=563885885, receiver_cell='rnn', receiver_embedding=10, receiver_hidden=100, receiver_layers=2, rnn=False, sender_cell='rnn', sender_embedding=10, sender_entropy_coeff=0.1, sender_hidden=100, sender_layers=2, temperature=1.0, tensorboard=False, tensorboard_dir='vs25_20210728-010622', train_data='../../data/sum5.train.train', update_freq=1, validation_batch_size=32, validation_data='../../data/sum5.train.val', validation_freq=20, vocab_size=25)\n",
      "# Initializing model, trainer, and optimizer from vs25_20210728-010622/final.tar\n",
      "# loading trainer state from vs25_20210728-010622/final.tar\n",
      "Namespace(batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, fp16=False, load_from_checkpoint='vs25_20210728-010603/final.tar', lr=0.001, max_len=1, mode='rf', n_attributes=None, n_epochs=1000, n_values=5, no_cuda=False, optimizer='adam', preemptable=False, print_validation_events=False, random_seed=2084409539, receiver_cell='rnn', receiver_embedding=10, receiver_hidden=100, receiver_layers=2, rnn=False, sender_cell='rnn', sender_embedding=10, sender_entropy_coeff=0.1, sender_hidden=100, sender_layers=2, temperature=1.0, tensorboard=False, tensorboard_dir='vs25_20210728-010603', train_data='../../data/sum5.train.train', update_freq=1, validation_batch_size=32, validation_data='../../data/sum5.train.val', validation_freq=20, vocab_size=25)\n",
      "# Initializing model, trainer, and optimizer from vs25_20210728-010603/final.tar\n",
      "# loading trainer state from vs25_20210728-010603/final.tar\n",
      "Namespace(batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, fp16=False, load_from_checkpoint='vs80_20210727-204031/final.tar', lr=0.001, max_len=1, mode='rf', n_attributes=None, n_epochs=1000, n_values=5, no_cuda=False, optimizer='adam', preemptable=False, print_validation_events=False, random_seed=2068691665, receiver_cell='rnn', receiver_embedding=10, receiver_hidden=100, receiver_layers=2, rnn=False, sender_cell='rnn', sender_embedding=10, sender_entropy_coeff=0.1, sender_hidden=100, sender_layers=2, temperature=1.0, tensorboard=False, tensorboard_dir='vs80_20210727-204031', train_data='../../data/sum5.train.train', update_freq=1, validation_batch_size=32, validation_data='../../data/sum5.train.val', validation_freq=20, vocab_size=80)\n",
      "# Initializing model, trainer, and optimizer from vs80_20210727-204031/final.tar\n",
      "# loading trainer state from vs80_20210727-204031/final.tar\n",
      "Namespace(batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, fp16=False, load_from_checkpoint='vs80_20210727-204501/final.tar', lr=0.001, max_len=1, mode='rf', n_attributes=None, n_epochs=1000, n_values=5, no_cuda=False, optimizer='adam', preemptable=False, print_validation_events=False, random_seed=1484564818, receiver_cell='rnn', receiver_embedding=10, receiver_hidden=100, receiver_layers=2, rnn=False, sender_cell='rnn', sender_embedding=10, sender_entropy_coeff=0.1, sender_hidden=100, sender_layers=2, temperature=1.0, tensorboard=False, tensorboard_dir='vs80_20210727-204501', train_data='../../data/sum5.train.train', update_freq=1, validation_batch_size=32, validation_data='../../data/sum5.train.val', validation_freq=20, vocab_size=80)\n",
      "# Initializing model, trainer, and optimizer from vs80_20210727-204501/final.tar\n",
      "# loading trainer state from vs80_20210727-204501/final.tar\n",
      "Namespace(batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, fp16=False, load_from_checkpoint='vs80_20210727-204926/final.tar', lr=0.001, max_len=1, mode='rf', n_attributes=None, n_epochs=1000, n_values=5, no_cuda=False, optimizer='adam', preemptable=False, print_validation_events=False, random_seed=2138330779, receiver_cell='rnn', receiver_embedding=10, receiver_hidden=100, receiver_layers=2, rnn=False, sender_cell='rnn', sender_embedding=10, sender_entropy_coeff=0.1, sender_hidden=100, sender_layers=2, temperature=1.0, tensorboard=False, tensorboard_dir='vs80_20210727-204926', train_data='../../data/sum5.train.train', update_freq=1, validation_batch_size=32, validation_data='../../data/sum5.train.val', validation_freq=20, vocab_size=80)\n",
      "# Initializing model, trainer, and optimizer from vs80_20210727-204926/final.tar\n",
      "# loading trainer state from vs80_20210727-204926/final.tar\n",
      "Namespace(batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, fp16=False, load_from_checkpoint='vs50_20210728-013138/final.tar', lr=0.001, max_len=1, mode='rf', n_attributes=None, n_epochs=1000, n_values=5, no_cuda=False, optimizer='adam', preemptable=False, print_validation_events=False, random_seed=490279938, receiver_cell='rnn', receiver_embedding=10, receiver_hidden=100, receiver_layers=2, rnn=False, sender_cell='rnn', sender_embedding=10, sender_entropy_coeff=0.1, sender_hidden=100, sender_layers=2, temperature=1.0, tensorboard=False, tensorboard_dir='vs50_20210728-013138', train_data='../../data/sum5.train.train', update_freq=1, validation_batch_size=32, validation_data='../../data/sum5.train.val', validation_freq=20, vocab_size=50)\n",
      "# Initializing model, trainer, and optimizer from vs50_20210728-013138/final.tar\n",
      "# loading trainer state from vs50_20210728-013138/final.tar\n",
      "Namespace(batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, fp16=False, load_from_checkpoint='vs25_20210728-010138/final.tar', lr=0.001, max_len=1, mode='rf', n_attributes=None, n_epochs=1000, n_values=5, no_cuda=False, optimizer='adam', preemptable=False, print_validation_events=False, random_seed=1487284161, receiver_cell='rnn', receiver_embedding=10, receiver_hidden=100, receiver_layers=2, rnn=False, sender_cell='rnn', sender_embedding=10, sender_entropy_coeff=0.1, sender_hidden=100, sender_layers=2, temperature=1.0, tensorboard=False, tensorboard_dir='vs25_20210728-010138', train_data='../../data/sum5.train.train', update_freq=1, validation_batch_size=32, validation_data='../../data/sum5.train.val', validation_freq=20, vocab_size=25)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Initializing model, trainer, and optimizer from vs25_20210728-010138/final.tar\n",
      "# loading trainer state from vs25_20210728-010138/final.tar\n",
      "Namespace(batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, fp16=False, load_from_checkpoint='vs50_20210728-013111/final.tar', lr=0.001, max_len=1, mode='rf', n_attributes=None, n_epochs=1000, n_values=5, no_cuda=False, optimizer='adam', preemptable=False, print_validation_events=False, random_seed=1111318823, receiver_cell='rnn', receiver_embedding=10, receiver_hidden=100, receiver_layers=2, rnn=False, sender_cell='rnn', sender_embedding=10, sender_entropy_coeff=0.1, sender_hidden=100, sender_layers=2, temperature=1.0, tensorboard=False, tensorboard_dir='vs50_20210728-013111', train_data='../../data/sum5.train.train', update_freq=1, validation_batch_size=32, validation_data='../../data/sum5.train.val', validation_freq=20, vocab_size=50)\n",
      "# Initializing model, trainer, and optimizer from vs50_20210728-013111/final.tar\n",
      "# loading trainer state from vs50_20210728-013111/final.tar\n",
      "Namespace(batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, fp16=False, load_from_checkpoint='vs50_20210728-013555/final.tar', lr=0.001, max_len=1, mode='rf', n_attributes=None, n_epochs=1000, n_values=5, no_cuda=False, optimizer='adam', preemptable=False, print_validation_events=False, random_seed=214064289, receiver_cell='rnn', receiver_embedding=10, receiver_hidden=100, receiver_layers=2, rnn=False, sender_cell='rnn', sender_embedding=10, sender_entropy_coeff=0.1, sender_hidden=100, sender_layers=2, temperature=1.0, tensorboard=False, tensorboard_dir='vs50_20210728-013555', train_data='../../data/sum5.train.train', update_freq=1, validation_batch_size=32, validation_data='../../data/sum5.train.val', validation_freq=20, vocab_size=50)\n",
      "# Initializing model, trainer, and optimizer from vs50_20210728-013555/final.tar\n",
      "# loading trainer state from vs50_20210728-013555/final.tar\n",
      "Namespace(batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, fp16=False, load_from_checkpoint='vs9_20210728-011549/final.tar', lr=0.001, max_len=1, mode='rf', n_attributes=None, n_epochs=1000, n_values=5, no_cuda=False, optimizer='adam', preemptable=False, print_validation_events=False, random_seed=2019145024, receiver_cell='rnn', receiver_embedding=10, receiver_hidden=100, receiver_layers=2, rnn=False, sender_cell='rnn', sender_embedding=10, sender_entropy_coeff=0.1, sender_hidden=100, sender_layers=2, temperature=1.0, tensorboard=False, tensorboard_dir='vs9_20210728-011549', train_data='../../data/sum5.train.train', update_freq=1, validation_batch_size=32, validation_data='../../data/sum5.train.val', validation_freq=20, vocab_size=9)\n",
      "# Initializing model, trainer, and optimizer from vs9_20210728-011549/final.tar\n",
      "# loading trainer state from vs9_20210728-011549/final.tar\n",
      "Namespace(batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, fp16=False, load_from_checkpoint='vs80_20210727-204039/final.tar', lr=0.001, max_len=1, mode='rf', n_attributes=None, n_epochs=1000, n_values=5, no_cuda=False, optimizer='adam', preemptable=False, print_validation_events=False, random_seed=597533213, receiver_cell='rnn', receiver_embedding=10, receiver_hidden=100, receiver_layers=2, rnn=False, sender_cell='rnn', sender_embedding=10, sender_entropy_coeff=0.1, sender_hidden=100, sender_layers=2, temperature=1.0, tensorboard=False, tensorboard_dir='vs80_20210727-204039', train_data='../../data/sum5.train.train', update_freq=1, validation_batch_size=32, validation_data='../../data/sum5.train.val', validation_freq=20, vocab_size=80)\n",
      "# Initializing model, trainer, and optimizer from vs80_20210727-204039/final.tar\n",
      "# loading trainer state from vs80_20210727-204039/final.tar\n"
     ]
    }
   ],
   "source": [
    "results = {}\n",
    "for exp_dir in Path(\".\").glob(\"vs*\"):\n",
    "    try:\n",
    "        game, opts = load_game(exp_dir)\n",
    "    except:\n",
    "        traceback.print_exc()\n",
    "        continue\n",
    "    results[str(exp_dir)] = {\n",
    "        \"vocab_size\": opts.vocab_size,\n",
    "    }\n",
    "    for split, data_loader in [(\"train\", train_loader), (\"test\", test_loader)]:\n",
    "        interaction = interact(game, data_loader)\n",
    "        results[str(exp_dir)][split + \"_acc\"] = balanced_accuracy(interaction)\n",
    "results = pd.DataFrame.from_dict(results, orient=\"index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vocab_size</th>\n",
       "      <th>train_acc</th>\n",
       "      <th>test_acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>vs9_20210728-011522</th>\n",
       "      <td>9</td>\n",
       "      <td>0.573016</td>\n",
       "      <td>0.142857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vs25_20210728-010145</th>\n",
       "      <td>25</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vs9_20210728-012513</th>\n",
       "      <td>9</td>\n",
       "      <td>0.748148</td>\n",
       "      <td>0.142857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vs25_20210728-011052</th>\n",
       "      <td>25</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vs9_20210728-012034</th>\n",
       "      <td>9</td>\n",
       "      <td>0.715873</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vs50_20210728-014041</th>\n",
       "      <td>50</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vs50_20210728-012642</th>\n",
       "      <td>50</td>\n",
       "      <td>0.748148</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vs9_20210728-011103</th>\n",
       "      <td>9</td>\n",
       "      <td>0.614815</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vs80_20210727-204454</th>\n",
       "      <td>80</td>\n",
       "      <td>0.977778</td>\n",
       "      <td>0.142857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vs25_20210728-010622</th>\n",
       "      <td>25</td>\n",
       "      <td>0.977778</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vs25_20210728-010603</th>\n",
       "      <td>25</td>\n",
       "      <td>0.968599</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vs80_20210727-204031</th>\n",
       "      <td>80</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vs80_20210727-204501</th>\n",
       "      <td>80</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vs80_20210727-204926</th>\n",
       "      <td>80</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vs50_20210728-013138</th>\n",
       "      <td>50</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vs25_20210728-010138</th>\n",
       "      <td>25</td>\n",
       "      <td>0.859259</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vs50_20210728-013111</th>\n",
       "      <td>50</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vs50_20210728-013555</th>\n",
       "      <td>50</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vs9_20210728-011549</th>\n",
       "      <td>9</td>\n",
       "      <td>0.696296</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vs80_20210727-204039</th>\n",
       "      <td>80</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      vocab_size  train_acc  test_acc\n",
       "vs9_20210728-011522            9   0.573016  0.142857\n",
       "vs25_20210728-010145          25   0.888889  0.000000\n",
       "vs9_20210728-012513            9   0.748148  0.142857\n",
       "vs25_20210728-011052          25   0.866667  0.000000\n",
       "vs9_20210728-012034            9   0.715873  0.000000\n",
       "vs50_20210728-014041          50   1.000000  0.000000\n",
       "vs50_20210728-012642          50   0.748148  0.000000\n",
       "vs9_20210728-011103            9   0.614815  0.000000\n",
       "vs80_20210727-204454          80   0.977778  0.142857\n",
       "vs25_20210728-010622          25   0.977778  0.000000\n",
       "vs25_20210728-010603          25   0.968599  0.000000\n",
       "vs80_20210727-204031          80   0.888889  0.000000\n",
       "vs80_20210727-204501          80   1.000000  0.000000\n",
       "vs80_20210727-204926          80   0.888889  0.000000\n",
       "vs50_20210728-013138          50   0.888889  0.000000\n",
       "vs25_20210728-010138          25   0.859259  0.000000\n",
       "vs50_20210728-013111          50   0.866667  0.000000\n",
       "vs50_20210728-013555          50   0.777778  0.000000\n",
       "vs9_20210728-011549            9   0.696296  0.000000\n",
       "vs80_20210727-204039          80   1.000000  0.000000"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_acc</th>\n",
       "      <th>test_acc</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vocab_size</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            train_acc  test_acc\n",
       "vocab_size                     \n",
       "9                   5         5\n",
       "25                  5         5\n",
       "50                  5         5\n",
       "80                  5         5"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.groupby(\"vocab_size\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>vocab_size</th>\n",
       "      <th colspan=\"3\" halign=\"left\">train_acc</th>\n",
       "      <th colspan=\"2\" halign=\"left\">test_acc</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>max</th>\n",
       "      <th>mean</th>\n",
       "      <th># perfect</th>\n",
       "      <th>max</th>\n",
       "      <th>mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9</td>\n",
       "      <td>0.748148</td>\n",
       "      <td>0.669630</td>\n",
       "      <td>0</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.057143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25</td>\n",
       "      <td>0.977778</td>\n",
       "      <td>0.912238</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>50</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.856296</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>80</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.951111</td>\n",
       "      <td>2</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.028571</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  vocab_size train_acc                      test_acc          \n",
       "                   max      mean # perfect       max      mean\n",
       "0          9  0.748148  0.669630         0  0.142857  0.057143\n",
       "1         25  0.977778  0.912238         0  0.000000  0.000000\n",
       "2         50  1.000000  0.856296         1  0.000000  0.000000\n",
       "3         80  1.000000  0.951111         2  0.142857  0.028571"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table = results.groupby(\"vocab_size\")[[\"train_acc\", \"test_acc\"]].agg([\"max\", \"mean\", lambda vals: (vals > 0.999).sum()]).drop((\"test_acc\", \"<lambda_0>\"), axis=1).rename(columns={\"<lambda_0>\": \"# perfect\"}).reset_index()\n",
    "table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{rrrrrr}\n",
      "\\toprule\n",
      "vocab\\_size & \\multicolumn{3}{l}{train\\_acc} & \\multicolumn{2}{l}{test\\_acc} \\\\\n",
      "           &       max & mean & \\# perfect &      max & mean \\\\\n",
      "\\midrule\n",
      "         9 &      0.75 & 0.67 &         0 &     0.14 & 0.06 \\\\\n",
      "        25 &      0.98 & 0.91 &         0 &     0.00 & 0.00 \\\\\n",
      "        50 &      1.00 & 0.86 &         1 &     0.00 & 0.00 \\\\\n",
      "        80 &      1.00 & 0.95 &         2 &     0.14 & 0.03 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with pd.option_context(\"display.precision\", 2):\n",
    "    print(table.to_latex(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "egg",
   "language": "python",
   "name": "egg"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
