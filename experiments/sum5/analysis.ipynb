{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import collections\n",
    "import itertools\n",
    "import shlex\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import torch\n",
    "\n",
    "import egg\n",
    "from egg.zoo.basic_games.data_readers import AttrValClassDataset\n",
    "from egg.zoo.basic_games import play_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_TRAIN = \"../../data/sum5.train.train\"\n",
    "PATH_VAL = \"../../data/sum5.train.val\"\n",
    "PATH_TEST = \"../../data/sum5.test\"\n",
    "N_VALUES = 5\n",
    "MAX_RESULT = 2 * (N_VALUES - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entropy(x_samples):\n",
    "    n = len(x_samples)\n",
    "    cx = collections.Counter(x_samples)\n",
    "    return -sum([cx[x] / n * np.log2(cx[x] / n) for x in cx])\n",
    "\n",
    "def cond_entropy(y_samples, x_samples):\n",
    "    assert len(x_samples) == len(y_samples)\n",
    "    n = len(x_samples)\n",
    "    cx = collections.Counter(x_samples)\n",
    "    cxy = collections.Counter(zip(x_samples, y_samples))\n",
    "    return -sum([cxy[x, y] / n * np.log2(cxy[x, y] / cx[x]) for x, y in cxy])\n",
    "\n",
    "def pointwise_mutual_information(x_samples, y_samples):\n",
    "    assert len(x_samples) == len(y_samples)\n",
    "    n = len(x_samples)\n",
    "    cx = collections.Counter(x_samples)\n",
    "    cy = collections.Counter(y_samples)\n",
    "    cxy = collections.Counter(zip(x_samples, y_samples))\n",
    "    return np.array([np.log2(cxy[x, y] * n / (cx[x] * cy[y])) for x, y in zip(x_samples, y_samples)])\n",
    "\n",
    "def mutual_information(x_samples, y_samples):\n",
    "    return pointwise_mutual_information(x_samples, y_samples).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_legend(ax, **kwargs):\n",
    "    old_legend = ax.legend_\n",
    "    handles = old_legend.legendHandles\n",
    "    labels = [t.get_text() for t in old_legend.get_texts()]\n",
    "    if \"title\" not in kwargs:\n",
    "        kwargs[\"title\"] = old_legend.get_title().get_text()\n",
    "    ax.legend(handles, labels, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a codebook of letter combinations to display instead of numbers for easier viewing\n",
    "codewords = [''.join(l) for l in itertools.product(*[[chr(i) for i in range(ord('a'), ord('z') + 1)]] * 2)]\n",
    "np.random.default_rng(1).shuffle(codewords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(batch_size=32, checkpoint_dir=None, checkpoint_freq=0, cuda=True, device=device(type='cuda'), distributed_context=DistributedContext(is_distributed=False, rank=0, local_rank=0, world_size=1, mode='none'), distributed_port=18363, fp16=False, load_from_checkpoint='vs50_20210728-014041/final.tar', lr=0.001, max_len=1, mode='rf', n_attributes=None, n_epochs=1000, n_values=5, no_cuda=False, optimizer='adam', preemptable=False, print_validation_events=False, random_seed=2134625598, receiver_cell='rnn', receiver_embedding=10, receiver_hidden=100, receiver_layers=2, rnn=False, sender_cell='rnn', sender_embedding=10, sender_entropy_coeff=0.1, sender_hidden=100, sender_layers=2, temperature=1.0, tensorboard=False, tensorboard_dir='vs50_20210728-014041', train_data='../../data/sum5.train.train', update_freq=1, validation_batch_size=32, validation_data='../../data/sum5.train.val', validation_freq=20, vocab_size=50)\n",
      "# Initializing model, trainer, and optimizer from vs50_20210728-014041/final.tar\n",
      "# loading trainer state from vs50_20210728-014041/final.tar\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SymbolGameReinforce(\n",
       "  (sender): ReinforceWrapper(\n",
       "    (agent): SumSender(\n",
       "      (net): Sequential(\n",
       "        (0): Linear(in_features=10, out_features=100, bias=True)\n",
       "        (1): ELU(alpha=1.0)\n",
       "        (2): Linear(in_features=100, out_features=50, bias=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (receiver): ReinforceDeterministicWrapper(\n",
       "    (agent): SymbolReceiverWrapper(\n",
       "      (agent): SumReceiver(\n",
       "        (net): Sequential(\n",
       "          (0): Linear(in_features=100, out_features=100, bias=True)\n",
       "          (1): ELU(alpha=1.0)\n",
       "          (2): Linear(in_features=100, out_features=9, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (embedding): RelaxedEmbedding(50, 100)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp_dir = \"vs50_20210728-014041\"\n",
    "\n",
    "with open(Path(exp_dir) / \"args\") as f:\n",
    "    args = shlex.split(f.read())\n",
    "opts = play_sum.get_params(args)\n",
    "\n",
    "# Make the trainer load the checkpoint instead of writing it\n",
    "assert opts.checkpoint_dir\n",
    "opts.load_from_checkpoint = str(Path(opts.checkpoint_dir) / \"final.tar\")\n",
    "opts.checkpoint_dir = None\n",
    "opts.tensorboard = False\n",
    "\n",
    "game = play_sum.main(args, opts=opts, train=False)\n",
    "game.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader = torch.utils.data.DataLoader(\n",
    "    AttrValClassDataset(\n",
    "        path=PATH_TRAIN,\n",
    "        n_values=opts.n_values,\n",
    "    ),\n",
    "    batch_size=opts.validation_batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "interaction = []\n",
    "for sender_input, labels in data_loader:\n",
    "    with torch.no_grad():\n",
    "        interaction.append(game(sender_input.cuda(), labels.cuda())[1].to(\"cpu\"))\n",
    "interaction = egg.core.Interaction.from_iterable(interaction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "aa = interaction.sender_input[:, :opts.n_values].argmax(dim=-1).numpy()\n",
    "bb = interaction.sender_input[:, opts.n_values:].argmax(dim=-1).numpy()\n",
    "rr = interaction.receiver_output.argmax(dim=-1).numpy()\n",
    "correct_mask = (aa + bb == rr)\n",
    "messages = np.array([codewords[msg] for msg in interaction.message.tolist()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_df = pd.DataFrame({\n",
    "    \"msg\": messages,\n",
    "    \"a\": aa,\n",
    "    \"b\": bb,\n",
    "    \"r\": rr,\n",
    "    \"acc\": aa + bb == rr,\n",
    "    \"ab\": list(zip(aa, bb)),\n",
    "    \"ab_unordered\": [tuple(sorted(x)) for x in zip(aa, bb)]}\n",
    ")\n",
    "correct_df = all_df[correct_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9128491025779536"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Normalized excess information\n",
    "cond_entropy(correct_df[\"msg\"], correct_df[\"r\"]) / cond_entropy(correct_df[\"ab\"], correct_df[\"r\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      mr\n",
       "1      nc\n",
       "2      sz\n",
       "3      ix\n",
       "4      vo\n",
       "       ..\n",
       "395    nc\n",
       "396    nc\n",
       "397    xn\n",
       "398    ro\n",
       "399    go\n",
       "Name: msg, Length: 400, dtype: category\n",
       "Categories (16, object): ['ay', 'cz', 'el', 'fw', ..., 'vo', 'xn', 'zb', 'zn']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct_df[\"msg\"].astype(\"category\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ay': [(0, 3)],\n",
       " 'cz': [(0, 4)],\n",
       " 'el': [(3, 1), (1, 3)],\n",
       " 'fw': [(2, 3)],\n",
       " 'go': [(2, 4)],\n",
       " 'ix': [(4, 2)],\n",
       " 'jb': [(4, 1)],\n",
       " 'kk': [(2, 2)],\n",
       " 'mr': [(1, 1)],\n",
       " 'nc': [(0, 0)],\n",
       " 'ro': [(1, 2)],\n",
       " 'sz': [(0, 1)],\n",
       " 'vo': [(4, 4)],\n",
       " 'xn': [(3, 4)],\n",
       " 'zb': [(2, 1)],\n",
       " 'zn': [(1, 4)]}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct_df[[\"msg\", \"ab\"]].drop_duplicates().groupby(\"msg\")[\"ab\"].apply(list).to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Commutativity: 0.25\n",
      "Min. number of commutative pairs per sum: 1\n"
     ]
    }
   ],
   "source": [
    "# Commutative property\n",
    "comm_df = correct_df.copy()\n",
    "# Keep only pairs that are in the dataset both ways\n",
    "ab_set = set(comm_df[\"ab\"].values)\n",
    "comm_df = comm_df[comm_df.apply(lambda row: tuple(reversed(row[\"ab\"])) in ab_set, axis=1)]\n",
    "comm_df = comm_df[[\"a\", \"b\", \"r\", \"msg\"]].drop_duplicates()\n",
    "comm_df = comm_df.groupby([\"a\", \"b\"]).first()\n",
    "comm_df = comm_df.sort_values([\"a\", \"b\"])\n",
    "comm_df[\"msg_ba\"] = comm_df.reset_index().rename(columns={\"a\": \"b\", \"b\": \"a\"}).set_index([\"a\", \"b\"])[\"msg\"]\n",
    "comm_df[\"comm\"] = (comm_df[\"msg\"] == comm_df[\"msg_ba\"])\n",
    "comm_df = comm_df.reset_index()\n",
    "comm_df = comm_df[comm_df[\"a\"] < comm_df[\"b\"]]  # Count each pair only once\n",
    "\n",
    "print(\"Commutativity:\", comm_df[\"comm\"].mean())\n",
    "print(\"Min. number of commutative pairs per sum:\", comm_df.groupby(\"r\")[\"comm\"].count().min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "egg",
   "language": "python",
   "name": "egg"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
